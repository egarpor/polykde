% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tests.R
\name{hom_test_poly}
\alias{hom_test_poly}
\title{Homogeneity test for two polyspherical samples}
\usage{
hom_test_poly(X, d, labels, type = c("mean", "scatter", "jsd", "hd")[1],
  h = NULL, kernel = 1, kernel_type = 1, k = 10, B = 1000,
  M = 10000, plot_boot = FALSE, seed_jsd = NULL, cv_jsd = TRUE)
}
\arguments{
\item{X}{a matrix of size \code{c(n, sum(d) + r)} with the sample.}

\item{d}{dimensions vector, of size \code{r}.}

\item{labels}{vector with \code{k} different levels indicating the group.}

\item{type}{kind of test to be performed: \code{"mean"}, a simple test
for the equality of both means (non-omnibus for testing homogeneity);
\code{"scatter"}, a simple test for the equality of both scatter matrices
(non-omnibus for testing homogeneity); \code{"hd"}/\code{"jsd"} a test
comparing the kernel density estimators for both groups using the Hellinger
distance/Jensen--Shannon distance.}

\item{h}{bandwidth vector, of size \code{r}.}

\item{kernel}{kernel employed: \code{1} for vMF (default); \code{2}
for Epa, \eqn{L(t) = (1 - t)1_{\{0 \le t \le 1\}}}; \code{3} for softplus.}

\item{kernel_type}{type of kernel employed: \code{1} for product kernel
(default); \code{2} for spherically symmetric kernel.}

\item{k}{softplus kernel parameter. Defaults to \code{10.0}.}

\item{B}{number of permutations to use.}

\item{M}{number of Monte Carlo replicates to use when approximating the
Hellinger/Jensen--Shannon distance.}

\item{plot_boot}{flag to display a graphical output of the test decision.}

\item{seed_jsd}{seed for the Monte Carlo simulations used to estimate the
integrals in the Jensen--Shannon distance.}

\item{cv_jsd}{use cross-validation to approximate the Jensen--Shannon
distance? Does not require Monte Carlo.}
}
\value{
TODO
}
\description{
Homogeneity test for two polyspherical samples
}
\details{
The \code{"mean"} statistic measures the maximum (chordal) distance
between the estimated group means. This statistic is bounded in \eqn{[0, 1]}.
The \code{"var"} statistic measures the maximum affine invariant Riemannian
metric between the estimated scatter matrices. The \code{"jsd"} statistic is
the Jensen--Shannon divergence. This statistic is bounded in \eqn{[0, 1]}.
The \code{"hd"} statistic computes a monotonic transformation of the
Hellinger distance, which is the Bhattacharyya divergence (or coefficient).
}
\examples{
## Two-sample case
\donttest{
# H0 holds
n <- c(50, 100)
X1 <- rotasym::r_vMF(n = n[1], mu = c(0, 0, 1), kappa = 1)
X2 <- rotasym::r_vMF(n = n[2], mu = c(0, 0, 1), kappa = 1)
hom_test_poly(X = rbind(X1, X2), labels = rep(1:2, times = n),
              d = 2, type = "jsd", h = 0.5, cv_jsd = 1)

# H0 does not hold
X2 <- rotasym::r_vMF(n = n[2], mu = c(0, 1, 0), kappa = 2)
hom_test_poly(X = rbind(X1, X2), labels = rep(1:2, times = n),
              d = 2, type = "jsd", h = 0.5, cv_jsd = 1)

## k-sample case

# H0 holds
n <- c(50, 100, 50)
X1 <- rotasym::r_vMF(n = n[1], mu = c(0, 0, 1), kappa = 1)
X2 <- rotasym::r_vMF(n = n[2], mu = c(0, 0, 1), kappa = 1)
X3 <- rotasym::r_vMF(n = n[3], mu = c(0, 0, 1), kappa = 1)
hom_test_poly(X = rbind(X1, X2, X3), labels = rep(1:3, times = n),
              d = 2, type = "jsd", h = 0.5, cv_jsd = 1)

# H0 does not hold
X3 <- rotasym::r_vMF(n = n[3], mu = c(0, 1, 0), kappa = 2)
hom_test_poly(X = rbind(X1, X2, X3), labels = rep(1:3, times = n),
              d = 2, type = "jsd", h = 0.5, cv_jsd = 1)
}
}
